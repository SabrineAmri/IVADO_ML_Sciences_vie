{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Prédiction du type de culture en fonction du sol et de la météo\n",
    "<br>\n",
    "<span style='font-size:20px'><center>\n",
    "<blockquote cite=\"https://www.kaggle.com/code/theeyeschico/crop-analysis-and-prediction/input\">Precision agriculture is in trend nowadays. It helps the farmers to get informed decision about the farming strategy. Here, I present you a dataset which would allow the users to build a predictive model to recommend the most suitable crops to grow in a particular farm based on various parameters.  This dataset was build by augmenting datasets of rainfall, climate and fertilizer data available for India.</center></blockquote>\n",
    "<a href='https://www.kaggle.com/code/theeyeschico/crop-analysis-and-prediction/input'> https://www.kaggle.com/code/theeyeschico/crop-analysis-and-prediction/input </a>\n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " <span style='font-size:20px'><center>\n",
    "Le but est de prédire (recommender) un type de culture en utilisant les données météo et de composition du sol. \n",
    "La tâche est une tâche de classification, le type de culture est l'étiquette.  Nous nous déplaçons dans une autre partie du monde, en Inde.\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Installation et chargement des librairies nécessaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "Nous devons d'abord charger (et possiblement installer) les librairies nécessaires.  Voici une description de certaines des librairies utilisées.\n",
    "\n",
    "- `missingo` permet de visualiser rapidement les données manquantes\n",
    "- `sklearn`  scikit-learn est un incontournable pour faire de l'apprentissage automatique\n",
    "- `matplotlib` et `seaborn` pour générer des graphiques\n",
    "- `numpy` pour des opérations d'algèbres linéaires et mathématiques\n",
    "- `pandas` pour faciliter la manipulation et la structure des données (parfois lent pour les gros jeux de données)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:34.908090Z",
     "start_time": "2023-07-18T12:23:31.562388Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install missingno\n",
    "#!pip install statsmodels\n",
    "#!pip install scikit-learn \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import missingno\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.ensemble import (RandomForestRegressor, RandomForestClassifier, BaggingRegressor,\n",
    "                              GradientBoostingRegressor, GradientBoostingClassifier)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, f1_score, mean_absolute_error,\n",
    "                            confusion_matrix, classification_report, roc_auc_score, recall_score)\n",
    "\n",
    "\n",
    "sns.set(font_scale=0.9, style='whitegrid')\n",
    "colors = [\"#40BEAD\", \"#248CC4\", \"#308E81\", \"#576AC9\"] # IVADO palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T22:54:45.237252Z",
     "start_time": "2023-07-14T22:54:45.233156Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:35.624336Z",
     "start_time": "2023-07-18T12:23:34.911754Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m myfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(myfile)\n\u001b[1;32m      3\u001b[0m mf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mf\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "myfile = ''\n",
    "mf = pd.read_csv(myfile)\n",
    "mf['label'] = mf.label.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regardons les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:35.668180Z",
     "start_time": "2023-07-18T12:23:35.631364Z"
    }
   },
   "outputs": [],
   "source": [
    "mf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T01:16:07.179886Z",
     "start_time": "2023-07-15T01:16:07.101715Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le jeu de données contient les caractéristiques suivantes: \n",
    "    \n",
    "* N - ratio of Nitrogen content in soil\n",
    "* P - ratio of Phosphorous content in soil\n",
    "* K - ratio of Potassium content in soil\n",
    "* temperature - temperature in degree Celsius\n",
    "* humidity - relative humidity in %\n",
    "* ph - ph value of the soil\n",
    "* rainfall - rainfall in mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## À votre tour  \n",
    "<span class='h1'> Break room - 10 min - en équipe </h4>\n",
    "\n",
    "\n",
    "<img style='float:right;'  src='https://drive.google.com/uc?export=view&id=1HMGzZe3dGBk9Zgpk0tKtbQarFu3WMrBK' width='100px'>  </a>\n",
    "\n",
    "Explorer les données à l'aide de graphiques et de tableaux (1-2 graphique(s))\n",
    "\n",
    "Suggestions : \n",
    "* Pairplot de seaborn\n",
    "* Graphique de distribution\n",
    "* Nombre de valeurs manquantes \n",
    "\n",
    "\n",
    "Qu'avez-vous observé ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> Nombre de valeurs manquantes </h3>\n",
    "\n",
    "Cela nous indique si nous devons ajouter une étape d'imputation des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:35.960087Z",
     "start_time": "2023-07-18T12:23:35.685589Z"
    }
   },
   "outputs": [],
   "source": [
    "missingno.matrix(mf, figsize=(6,3), fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> Nombre d'exemples par classe </h3>\n",
    "\n",
    "Cela nous indique si les classes sont bien balancées. Lorsque les classes sont débalancées, nous devons nous assurer d'ajuster notre *baseline* et notre définition de succès.  Nous devons aussi prendre des précautions au niveau de la validation croisée.\n",
    "<center>\n",
    "<img src='https://user.oc-static.com/upload/2017/02/27/14881893858847_P2C2-3.png' width='400px'/> </center>\n",
    "\n",
    "\n",
    "<a style='font-size:16px;' href='https://openclassrooms.com/fr/courses/4297211-evaluez-les-performances-dun-modele-de-machine-learning/4308241-mettez-en-place-un-cadre-de-validation-croisee'>https://openclassrooms.com/fr/courses/4297211-evaluez-les-performances-dun-modele-de-machine-learning/4308241-mettez-en-place-un-cadre-de-validation-croisee</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:36.363096Z",
     "start_time": "2023-07-18T12:23:35.963315Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "mf.label.value_counts().plot(kind='bar', title=\"Nombre d'exemples par classe\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T23:01:13.681121Z",
     "start_time": "2023-07-14T23:01:13.674285Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> Valeur moyenne de chaque caractéristique par classe </h3>\n",
    "\n",
    "Cela nous donne une idée de la variabilité pour chacune des classes.  Par exemple, nous pouvons tout de suite présumer que le ph sera peu informatif et peu utile pour discriminer les différentes sortes de cultures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:38.811871Z",
     "start_time": "2023-07-18T12:23:36.366456Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nc = 4\n",
    "nr = math.ceil((mf.shape[1]/nc)+1)\n",
    "g = mf.groupby('label')\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "for i,col in enumerate(list(mf.columns)): \n",
    "    if col=='label':\n",
    "        continue\n",
    "    plt.subplot(nr,nc,i+1)\n",
    "    g.mean()[col].sort_values().plot(kind='barh', title=col) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualisation par radar plot\n",
    "\n",
    "Nous permet de comparer directement plusieurs classes en regardant des caractérisitques choisies.  Cette visualisation s'avère utile pour les petits jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:38.828034Z",
     "start_time": "2023-07-18T12:23:38.814842Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.pythoncharts.com/matplotlib/radar-charts/\n",
    "def radarplot(crop, color='doderblue', ax=None):\n",
    "    g = mf.groupby('label').mean()\n",
    "    features = g.columns\n",
    "    # Normalisation\n",
    "    g = (g - g.min(0)) / (g.max(0) - g.min(0))\n",
    "    values = g.loc[crop, :].values\n",
    "    num_features = len(features)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_features, endpoint=False).tolist()\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(3, 3), subplot_kw=dict(polar=True))\n",
    "\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_thetagrids(np.degrees(angles), features)\n",
    "\n",
    "    for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "        if angle in (0, np.pi):\n",
    "            label.set_horizontalalignment('center')\n",
    "        elif 0 < angle < np.pi:\n",
    "            label.set_horizontalalignment('left')\n",
    "        else:\n",
    "            label.set_horizontalalignment('right')\n",
    "   \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_rlabel_position(180 / num_features)\n",
    "    ax.tick_params(colors='#222222')\n",
    "    ax.tick_params(axis='y', labelsize=8)\n",
    "    ax.grid(color='#AAAAAA')\n",
    "    ax.spines['polar'].set_color('#222222')\n",
    "    ax.set_facecolor('#FAFAFA')\n",
    "    ax.plot(angles, values, color=color, linewidth=1, label=crop)\n",
    "    ax.fill(angles, values, color=color, alpha=0.25)\n",
    "    ax.set_title(F\"Caractéristiques\", y=1.18)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:23:39.160713Z",
     "start_time": "2023-07-18T12:23:38.832664Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = radarplot('rice', color='grey')\n",
    "ax = radarplot('apple', color='red', ax=ax)\n",
    "ax = radarplot('grapes', color='purple', ax=ax)\n",
    "ax = radarplot('chickpea', color='beige', ax=ax)\n",
    "plt.legend(bbox_to_anchor=(1.8, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:12.831044Z",
     "start_time": "2023-07-18T12:23:39.167348Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(mf, hue='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:14.205309Z",
     "start_time": "2023-07-18T12:24:12.833839Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"rainfall\", y=\"humidity\", data=mf, hue=\"label\")\n",
    "plt.legend(bbox_to_anchor=(1.15, 1), ncol=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-14T23:19:40.265212Z",
     "start_time": "2023-07-14T23:19:40.122781Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification du type de culture en fonction des donneés du sol et de météo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:14.219960Z",
     "start_time": "2023-07-18T12:24:14.208267Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = mf.drop('label', axis=1)\n",
    "y = mf.label.cat.codes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:24:14.659479Z",
     "start_time": "2023-07-18T12:24:14.224232Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(X_train.corr(), annot=True, fmt=\".1f\", cmap='GnBu', linewidths=.5, annot_kws={\"size\": 10}).set(title='Correlation Matrix (Train)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recherche du meilleur modèle et de ses paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:08.496534Z",
     "start_time": "2023-07-18T12:24:14.663107Z"
    }
   },
   "outputs": [],
   "source": [
    "# environ 2-3 min\n",
    "estimator_params = {'RandomForestClassifier': {'estimator__max_depth': [4, 6, 8, 10, 12]},\n",
    "                    'SVC' : {'estimator__kernel':  ['poly', 'rbf', 'sigmoid']},\n",
    "                    'DecisionTreeClassifier': {},\n",
    "                    'KNeighborsClassifier':{},\n",
    "                    'DummyClassifier': {}                      \n",
    "}\n",
    "\n",
    "res = []\n",
    "for estimator in estimator_params.keys():\n",
    "    parameters = {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "        'imputer': [SimpleImputer(), IterativeImputer()],\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', None), ('scaler', None), ('estimator', eval(estimator)()) \n",
    "    ])\n",
    "    parameters.update(estimator_params.get(estimator, {}))\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring=\"accuracy\")  \n",
    "    grid_search.fit(X_train, y_train) \n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_estimator = grid_search.best_estimator_     \n",
    "    res.append([estimator, grid_search.best_score_, grid_search.best_params_, cv_results, best_estimator]) \n",
    "res = pd.DataFrame(res, columns=['Model', 'Best_Score', 'Best_parameters', 'CV_Results', 'Best_estimator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regardons les résultats obtenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:08.711433Z",
     "start_time": "2023-07-18T12:25:08.499285Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:53:57.932283Z",
     "start_time": "2023-07-16T01:53:57.431224Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparaison des modèles \n",
    "\n",
    "Nous pouvons utiliser le `Best_score` pour identifier le meilleur modèle.  Il est intéressant de regarder plusieurs métriques car chacune des métriques nous renseigne sur des aspects différents.  Nous devons aussi considérer les contraintes pratiques dans notre choix, comme par exemple le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:09.208118Z",
     "start_time": "2023-07-18T12:25:08.715829Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_names = [\"accuracy_score\", \"recall_score\"] # même nom que dans la librairie\n",
    "mymetrics = []\n",
    "for row in res.to_dict('records'):\n",
    "    model = row['Model']\n",
    "    time = row['CV_Results']['mean_fit_time'].mean()+row['CV_Results']['mean_score_time'].mean()\n",
    "    estimator = row['Best_estimator']\n",
    "    pred_test = estimator.fit(X_train, y_train).predict(X_test)\n",
    "    m = []\n",
    "    for metric_name in metric_names:\n",
    "        try:\n",
    "            m.append(eval(f'{metric_name}(y_test, pred_test)'))    \n",
    "        except:\n",
    "            m.append(eval(f'{metric_name}(y_test, pred_test, average=\"weighted\")'))  \n",
    "    mymetrics.append([model, time ] + m)\n",
    "mymetrics =  pd.DataFrame(mymetrics, columns=['Model', 'Time'] + metric_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:09.225481Z",
     "start_time": "2023-07-18T12:25:09.210828Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Regardons les valeurs des métriques\n",
    "mymetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:09.531936Z",
     "start_time": "2023-07-18T12:25:09.231121Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "vars = [\"accuracy_score\", \"Time\"]\n",
    "mx = mymetrics.iloc[:-1,:]\n",
    "px = mx[vars[0]]\n",
    "py = mx[vars[1]]\n",
    "plt.scatter(px, py)\n",
    "for i in range(len(px)):\n",
    "    plt.text(px[i], py[i], s=mx.Model[i])\n",
    "plt.xlabel(F'{vars[0].split(\"_\")[0].title()}')\n",
    "plt.xlabel(F'{vars[1].split(\"_\")[0].title()}')\n",
    "plt.title('Comparaison des modèles selon des métriques choisies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:53:59.067026Z",
     "start_time": "2023-07-16T01:53:59.066988Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nous pouvons regarder la matrice de confusion d'un modèle en particulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:09.953343Z",
     "start_time": "2023-07-18T12:25:09.536790Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = res.loc[res.Model=='RandomForestClassifier', 'Best_estimator'][0]\n",
    "classifier.fit(X_train, y_train)\n",
    "test_score = classifier.score(X_test, y_test)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(F'RandomForestClassifier {test_score:3.3}')\n",
    "print(classification_report(y_test, y_pred, target_names=mf.label.cat.categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:53:59.071347Z",
     "start_time": "2023-07-16T01:53:59.071320Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regardons maintenant les caractéristiques les plus importantes pour le modèle `RandomForestClassifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:10.208496Z",
     "start_time": "2023-07-18T12:25:09.957354Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4), dpi=80)\n",
    "c_features = len(X_train.columns)\n",
    "plt.barh(range(c_features), classifier.steps[2][1].feature_importances_)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature name\")\n",
    "plt.yticks(np.arange(c_features), X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:53:59.074576Z",
     "start_time": "2023-07-16T01:53:59.074549Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Il est utile de créer quelques fonctions pour visualiser les résultats obtenus.  Cela nous aide à évaluer la qualité des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:10.225052Z",
     "start_time": "2023-07-18T12:25:10.213014Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_probabilities_heatmap(X_test, classifier, labels):\n",
    "    sns.heatmap(classifier.predict_proba(X_test), cmap='viridis', xticklabels=labels, \n",
    "                yticklabels=False, cbar=True).set(title='Predicted Probabilities')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_probalities_points(X_test, classifier, labels):\n",
    "    sns.set(font_scale=0.9, style='whitegrid')\n",
    "    tmp = pd.DataFrame(classifier.predict_proba(X_test), columns=labels)\n",
    "    ix = tmp.quantile(0.90, 0).sort_values()\n",
    "    tmp = tmp.loc[:, ix.index]\n",
    "    sns.catplot(data=tmp, height=4, aspect=1.6, palette='tab20b').set(title='Predicted Probabilities')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:10.264153Z",
     "start_time": "2023-07-18T12:25:10.250057Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(X_test, y_test, classifier, labels):\n",
    "    mat = confusion_matrix(y_test, classifier.predict(X_test))\n",
    "    df_cm = pd.DataFrame(mat, list(labels), list(labels))\n",
    "    sns.set(font_scale=1.0) # for label size\n",
    "    fig, ax = plt.subplots(figsize=(8,5)) \n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, cmap=\"terrain\", ax=ax).set(title='Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T01:53:59.077280Z",
     "start_time": "2023-07-16T01:53:59.077254Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regardons maintenant les résultats de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:10.748380Z",
     "start_time": "2023-07-18T12:25:10.267562Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_probabilities_heatmap(X_test, classifier, labels=mf.label.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:11.496176Z",
     "start_time": "2023-07-18T12:25:10.753123Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_probalities_points(X_test, classifier, labels=mf.label.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:12.801279Z",
     "start_time": "2023-07-18T12:25:11.500027Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(X_test, y_test, classifier, labels=mf.label.cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### À votre tour  \n",
    "<img style='float:right;'  src='https://drive.google.com/uc?export=view&id=1HMGzZe3dGBk9Zgpk0tKtbQarFu3WMrBK' width='100px'>  </a>\n",
    "\n",
    "Que concluez-vous de ces graphiques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "L'exactitude est souvent rapportée comme métrique pour les tâches de classification.  Cela nous indique la proportion d'exemples qui ont été bien prédits, i.e. combien de prédictions sont correctes. \n",
    "\n",
    "Attention, par contre, aux jeux de données où les classes ne sont pas bien balancées.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La courbe ROC présente la sensibilité (True Positive Rate - TPR) en fonction de 1 - spécificité (False positive rate - FPR).  Elle permet aussi de comparer différents modèles.\n",
    "\n",
    "<a title=\"MartinThoma, CC0, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Roc-draft-xkcd-style.svg\"><img width=\"512\" alt=\"Roc-draft-xkcd-style\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Roc-draft-xkcd-style.svg/512px-Roc-draft-xkcd-style.svg.png\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:13.008088Z",
     "start_time": "2023-07-18T12:25:12.804758Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T12:25:13.353477Z",
     "start_time": "2023-07-18T12:25:13.010710Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "i = 20 \n",
    "category = mf.label.cat.categories[i]\n",
    "y_test_i = y_test==i\n",
    "\n",
    "probs = classifier.predict_proba(X_test)\n",
    "preds = probs[:,i]\n",
    "fpr, tpr, threshold = roc_curve(y_test_i, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title(f'Receiver Operating Characteristic - {category}')\n",
    "plt.plot(fpr, tpr, 'b', label = 'RandomForest AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "\n",
    "classifier2 = res.loc[res.Model=='KNeighborsClassifier', 'Best_estimator'].values[0]\n",
    "probs = classifier2.predict_proba(X_test)\n",
    "preds = probs[:,i]\n",
    "fpr, tpr, threshold = roc_curve(y_test_i, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title(f'Receiver Operating Characteristic - {category}')\n",
    "plt.plot(fpr, tpr, label = 'KNeighbors AUC = %0.2f' % roc_auc, color='dodgerblue'\n",
    ")\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quelques notebooks utilisant le même jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas toujours parfaits, mais c'est utile de lire le code des autres pour apprendre et se garder à jour.\n",
    "\n",
    "* https://www.kaggle.com/code/altafk/real-time-crop-recommendation\n",
    "* https://www.kaggle.com/code/ysthehurricane/crop-recommendation-system-using-lightgbm\n",
    "* https://www.kaggle.com/code/atharvaingle/what-crop-to-grow\n",
    "* https://github.com/the-pinbo/crop-prediction"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "511.2867431640625px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
